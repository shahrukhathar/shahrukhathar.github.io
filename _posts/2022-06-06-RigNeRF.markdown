---
layout: post
title: 'RigNeRF: Fully Controllable Neural 3D Portraits'
author: ShahRukh Athar, Zexiang Xu, Kalyan Sunkavalli , Eli Shechtman and Zhixin Shu
youtubeId: q-SdWAfhVSM
youtubeIdR: mEuqGy1ZlMA
---
<head>
  <title>RigNeRF: Fully Controllable Neural 3D Portraits</title>
</head>
<p>
<a href="http://shahrukhathar.github.io/about/" target="_blank">ShahRukh Athar</a>,
<a href="https://cseweb.ucsd.edu/~zex014/" target="_blank">Zexiang Xu</a>,
<a href="http://www.kalyans.org/">Kalyan Sunkavalli</a>,
<a href="https://research.adobe.com/person/eli-shechtman/" target="_blank">Eli Shechtman</a> and
<a href="https://zhixinshu.github.io/" target="_blank">Zhixin Shu</a> 
</p>
<br>
<br>

<div align="center">
  <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.html">
    <figure style="display:inline-block;">
      <img height="100" width="78" src="/images/RigNeRF/paper-thumb.png">
      <figcaption>Paper</figcaption>
  </figure>
  </a>
</div>

<div class="embed-container" style="position:relative;padding-bottom:41.56%;">
<video  style="width:100%;height:100%;position:absolute;left:0px;top:0px;" src="/videos/RigNeRF/RigNeRF-Video-captions.mp4" poster="/videos/RigNeRF/Thumbnail.png" controls>
  This is fallback content to display for user agents that do not support the video tag.
</video>
</div>
<div align="center">
  <br>
  <p style="font-size:12px"><i><a href="https://www.youtube.com/watch?v=q-SdWAfhVSM">YouTube link (Lower-Res, with captions)</a></i></p>
  <br>
  <br>
</div>

<br>
<div align="center">
  <br>
  <p style="font-size:17px"><i><b>TL;DR </b> RigNeRF enables control over facial expressions, head-pose and viewing direction of portrait neural radiance fields.</i></p>
  <br>
  <br>
</div>

<br>
<div align="center">
<br>
<h1 style="text-align: center">Abstract</h1>
</div>

Volumetric neural rendering methods, such as neural radiance fields (NeRFs), have enabled photo-realistic novel view synthesis. However, in their standard form, NeRFs do not support the editing of objects, such as a human head, within a scene. In this work, we propose RigNeRF, a system that goes beyond just novel view synthesis and enables full control of head pose and facial expressions learned from a single portrait video. We model changes in head pose and facial expressions using a deformation field that is guided by a 3D morphable face model (3DMM). The 3DMM effectively acts as a prior for RigNeRF that learns to predict only residuals to the 3DMM deformations and allows us to render novel (rigid) poses and (non-rigid) expressions that were not present in the input sequence. Using only a smartphone-captured short video of a subject for training, we demonstrate the effectiveness of our method on free view synthesis of a portrait scene with explicit head pose and expression controls.

<br>
<div align="center">
<br>
<h1 style="text-align: center">Some Results</h1>
</div>
Below we show reanimation results across different subjects.

<div class="embed-container" style="position:relative;padding-bottom:41.56%;">
<video  style="width:100%;height:100%;position:absolute;left:0px;top:0px;" src="/videos/RigNeRF/RigNeRF-Results.mp4" poster="/videos/RigNeRF/Thumbnail.png" controls>
  This is fallback content to display for user agents that do not support the video tag.
</video>
</div>
<div align="center">
  <br>
  <p style="font-size:12px"><i><a href="https://www.youtube.com/watch?v=mEuqGy1ZlMA">YouTube link (Lower-Res)</a></i></p>
  <br>
  <br>
</div>

<br>
<div align="center">
<br>
<h1 style="text-align: center">Citation</h1>
</div>

```
@inproceedings{athar2022rignerf,
  title={RigNeRF: Fully Controllable Neural 3D Portraits},
  author={Athar, ShahRukh and Xu, Zexiang and Sunkavalli, Kalyan and Shechtman, Eli and Shu, Zhixin},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year = {2022}
}
```